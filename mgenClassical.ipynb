{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sn715/RandomModel/blob/main/mgenClassical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please don't open it.\n",
        "\n",
        "Manual: please navigate to \"app\" section and click on dropdown to select music type. "
      ],
      "metadata": {
        "id": "4dAtoe2AcKid"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A07kzjx2iTsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50036026-e7a0-4653-8cb2-557b5e92de1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#library for understanding music\n",
        "from music21 import *\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import *\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "functions:"
      ],
      "metadata": {
        "id": "g6TsxanP7pyr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gjUebmlybEwl"
      },
      "outputs": [],
      "source": [
        "#@title READ MIDI\n",
        "def read_midi(file):\n",
        "    \n",
        "    print(\"Loading Music File:\",file)\n",
        "    \n",
        "    notes=[]\n",
        "    notes_to_parse = None\n",
        "    \n",
        "    #parsing a midi file\n",
        "    midi = converter.parse(file)\n",
        "  \n",
        "    #grouping based on different instruments\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "\n",
        "    #Looping over all the instruments\n",
        "    for part in s2.parts:\n",
        "    \n",
        "        #select elements of only piano\n",
        "        #if 'Piano' in str(part): \n",
        "        \n",
        "        notes_to_parse = part.recurse() \n",
        "  \n",
        "        #finding whether a particular element is note or a chord\n",
        "        for element in notes_to_parse:\n",
        "            \n",
        "            #note\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            \n",
        "            #chord\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return np.array(notes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CREATE FINAL DATA\n",
        "def createMusicData(musicPath):\n",
        "  \n",
        "    #read all the filenames\n",
        "    files=[i for i in os.listdir(musicPath) ]\n",
        "\n",
        "    #reading each midi file\n",
        "    notes_array = np.array([read_midi(musicPath+i) for i in files])\n",
        "\n",
        "    #converting 2D array into 1D array\n",
        "    notes_ = [element for note_ in notes_array for element in note_]\n",
        "\n",
        "    #No. of unique notes\n",
        "    unique_notes = list(set(notes_))\n",
        "\n",
        "    freq = dict(Counter(notes_))\n",
        "    frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
        "\n",
        "    #concatenating all 100 audio files\n",
        "    new_music=[]\n",
        "\n",
        "    for notes in notes_array:\n",
        "        temp=[]\n",
        "        for note_ in notes:\n",
        "            if note_ in frequent_notes:\n",
        "                temp.append(note_)            \n",
        "        new_music.append(temp)\n",
        "        \n",
        "    new_music = np.array(new_music)\n",
        "\n",
        "    #cutting all files to 1000\n",
        "    diff = 0\n",
        "\n",
        "    for i in range(100):\n",
        "        diff = len(new_music[i]) - 1000\n",
        "        if (diff > 0):\n",
        "          new_music[i] = new_music[i][:-diff]\n",
        "        elif (diff < 0):\n",
        "          for j in range(-diff):\n",
        "            new_music[i].append(0)\n",
        "\n",
        "    list(set(new_music.ravel()[0]))\n",
        "\n",
        "\n",
        "    #DICTIONARY unique notes --> numbers\n",
        "    #unique_x = np.unique(np.asarray([new_music[i][0:1001] for i in range(100)]).reshape(-1))\n",
        "    #x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))\n",
        "    #predicted_notes = [x_int_to_note[i] for i in intSong]\n",
        "\n",
        "    #preparing input sequences\n",
        "    x_seq=[]\n",
        "    for i in new_music:\n",
        "        temp=[]\n",
        "        for j in i:\n",
        "            #assigning unique integer to every note\n",
        "            temp.append(x_note_to_int[str(j)])\n",
        "        x_seq.append(temp)\n",
        "\n",
        "    x_seq = np.array(x_seq)\n",
        "\n",
        "    x = []\n",
        "    window_size = 32 #increase\n",
        "    for i in tqdm(x_seq):\n",
        "        this_x_ = [] # placeholder\n",
        "        for j in range(len(i)-window_size):\n",
        "            this_x_.append(i[j:(j+window_size)])\n",
        "        x.append(this_x_)\n",
        "\n",
        "    x_arr = np.asarray(x)\n",
        "    x_arr_resh = x_arr.reshape((100, 968, 32, 1))\n",
        "\n",
        "    bigX, bigY = x_arr_resh[:, 0:967, :, :], x_arr_resh[:, 967, :, :]\n",
        "    bigY = bigY.reshape((100, 32))\n",
        "\n",
        "    return bigX, bigY"
      ],
      "metadata": {
        "id": "3m_tR9EfxrIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title EMOTION DATA\n",
        "#CSV DATA\n",
        "\n",
        "def createEmotionData(emotionData):\n",
        "\n",
        "    new_data = emotionData.groupby('track id').mean().round(0)\n",
        "    new_data['track_id'] = new_data.index\n",
        "    final_data = new_data[['track_id', 'calmness', 'power']]\n",
        "\n",
        "    return final_data\n"
      ],
      "metadata": {
        "id": "w91x7WL7l13M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createData(musicPath, emotionData):\n",
        "\n",
        "      \n",
        "    #read all the filenames\n",
        "    files=[i for i in os.listdir(musicPath) ]\n",
        "\n",
        "    #reading each midi file\n",
        "    notes_array = np.array([read_midi(musicPath+i) for i in files])\n",
        "\n",
        "    #converting 2D array into 1D array\n",
        "    notes_ = [element for note_ in notes_array for element in note_]\n",
        "\n",
        "    #No. of unique notes\n",
        "    unique_notes = list(set(notes_))\n",
        "\n",
        "    freq = dict(Counter(notes_))\n",
        "    frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
        "\n",
        "    #concatenating all 100 audio files\n",
        "    new_music=[]\n",
        "\n",
        "    for notes in notes_array:\n",
        "        temp=[]\n",
        "        for note_ in notes:\n",
        "            if note_ in frequent_notes:\n",
        "                temp.append(note_)            \n",
        "        new_music.append(temp)\n",
        "        \n",
        "    new_music = np.array(new_music)\n",
        "\n",
        "    #cutting all files to 1000\n",
        "    diff = 0\n",
        "\n",
        "    for i in range(100):\n",
        "        diff = len(new_music[i]) - 1000\n",
        "        if (diff > 0):\n",
        "          new_music[i] = new_music[i][:-diff]\n",
        "        elif (diff < 0):\n",
        "          for j in range(-diff):\n",
        "            new_music[i].append(0)\n",
        "\n",
        "    list(set(new_music.ravel()[0]))\n",
        "\n",
        "\n",
        "    #DICTIONARY unique notes --> numbers\n",
        "    #unique_x = np.unique(np.asarray([new_music[i][0:1001] for i in range(100)]).reshape(-1))\n",
        "    #x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))\n",
        "    #predicted_notes = [x_int_to_note[i] for i in intSong]\n",
        "\n",
        "    #preparing input sequences\n",
        "    x_seq=[]\n",
        "    for i in new_music:\n",
        "        temp=[]\n",
        "        for j in i:\n",
        "            #assigning unique integer to every note\n",
        "            temp.append(x_note_to_int[str(j)])\n",
        "        x_seq.append(temp)\n",
        "\n",
        "    x_seq = np.array(x_seq)\n",
        "\n",
        "    x = []\n",
        "    window_size = 32 #increase\n",
        "    for i in tqdm(x_seq):\n",
        "        this_x_ = [] # placeholder\n",
        "        for j in range(len(i)-window_size):\n",
        "            this_x_.append(i[j:(j+window_size)])\n",
        "        x.append(this_x_)\n",
        "\n",
        "    x_arr = np.asarray(x)\n",
        "    x_arr_resh = x_arr.reshape((100, 968, 32, 1))\n",
        "\n",
        "    bigX, bigY = x_arr_resh[:, 0:967, :, :], x_arr_resh[:, 967, :, :]\n",
        "    bigY = bigY.reshape((100, 32))\n",
        "\n",
        "    #CSV\n",
        "\n",
        "    new_data = emotionData.groupby('track id').mean().round(0)\n",
        "    new_data['track_id'] = new_data.index\n",
        "    final_data = new_data[['track_id', 'calmness', 'power']]\n",
        "\n",
        "    return bigX, bigY, final_data"
      ],
      "metadata": {
        "id": "8tPNmD5TeKqH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title PREDICT\n",
        "def predict(music, emotion, model):\n",
        "    output_of_ONE_SONG = model.predict([music[0:1], emotion[0:1]])\n",
        "    intSong = list(np.round(output_of_ONE_SONG[0]*100, ).astype(int))\n",
        "\n",
        "    unique_x = np.unique(np.asarray([new_music[i][0:1001] for i in range(100)]).reshape(-1))\n",
        "    x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
        "    predicted_notes = [x_int_to_note[i] for i in intSong]\n",
        "\n",
        "    return predicted_notes"
      ],
      "metadata": {
        "id": "YDYe7CP1x5EI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYzC2QHQYgcs",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title CONVERT TO MIDI\n",
        "def convert_to_midi(prediction_output):\n",
        "   \n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        \n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                \n",
        "                cn=int(current_note)\n",
        "                new_note = note.Note(cn)\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "                \n",
        "                     \n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "            \n",
        "        # pattern is a note\n",
        "        else:\n",
        "            \n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 1\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='music.mid')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jFP09TGbAg2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ypyUfUAvewM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title BUILD MODEL\n",
        "def build_seamise_model_with_functional():\n",
        "    \n",
        "    # instantiate the input Tensor\n",
        "    input_layer = tf.keras.Input(shape=(967, 32, 1))\n",
        "    input_layer_aux = tf.keras.Input(shape=[3]) # try () or []\n",
        "    \n",
        "    # stack the layers using the syntax: new_layer()(previous_layer)\n",
        "    convlayer = tf.keras.layers.Conv2D(128, (10,2))(input_layer)\n",
        "    convlayer2 = tf.keras.layers.Conv2D(128, (10,2))(convlayer)\n",
        "    flatten_layer = tf.keras.layers.Flatten()(convlayer2)\n",
        "    # flatten_layer_aux = tf.keras.layers.Flatten()(input_layer_aux)\n",
        "    first_dense = tf.keras.layers.Dense(128, activation=tf.nn.relu)(flatten_layer)\n",
        "    second_dense = tf.keras.layers.Dense(128, activation=tf.nn.relu)(first_dense)\n",
        "    third_dense = tf.keras.layers.Dense(128, activation=tf.nn.relu)(second_dense)\n",
        "    concate = tf.keras.layers.Concatenate()([third_dense, input_layer_aux])\n",
        "    output_layer = tf.keras.layers.Dense(32)(concate)\n",
        "    \n",
        "    # declare inputs and outputs\n",
        "    # from tensorflow.keras.models import Model\n",
        "    func_model = tf.keras.models.Model(inputs=[input_layer, input_layer_aux], outputs=output_layer)\n",
        "    \n",
        "    return func_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8PY7ItZ1E35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "5ac31721-17b4-48b0-9b34-06cc315dd3fd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-970b2ba88fcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     history = model.fit(\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbigX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbigY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bigX' is not defined"
          ]
        }
      ],
      "source": [
        "#@title CREATE MODEL\n",
        "#define model\n",
        "tf.keras.backend.clear_session()\n",
        "model = build_seamise_model_with_functional()\n",
        "tf.keras.utils.plot_model(model)\n",
        "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0005,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name='adam',\n",
        ")\n",
        "\n",
        "model.compile(optimizer=opt, loss='mae') #, metrics=[tf.keras.metrics.Accuracy()])\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    history = model.fit(\n",
        "        x=[bigX, final_data],\n",
        "        y=bigY,\n",
        "        validation_split = 0.2,\n",
        "        batch_size=3,\n",
        "        epochs=7,\n",
        "        callbacks=[callback])\n",
        "    \n",
        "model.save('your_neuralnet_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MAGIC FUNCTION\n",
        "def magic_function():\n",
        "    if genre == 'classical' and emotion =='relaxation':\n",
        "        # Recreate the exact same model, including its weights and the optimizer\n",
        "        new_model = tf.keras.models.load_model('/content/drive/MyDrive/emotifymusicMD/your_neuralnet_model.h5')\n",
        "\n",
        "    musicPath =\"/content/drive/MyDrive/classicalmidi/\"\n",
        "\n",
        "    #/content/drive/MyDrive/emotifymusicMD/emotifyannotationsdata.csv\n",
        "    csvPath = '/content/drive/MyDrive/emotifymusicMD/'\n",
        "    os.chdir(csvPath)\n",
        "    #os.listdir()\n",
        "\n",
        "    annot = pd.read_csv('emotifyannotationsdata.csv', nrows = 2688)\n",
        "    annot.columns = ['track id', 'genre', 'amazement', 'solemnity', 'tenderness',\n",
        "          'nostalgia', 'calmness', 'power', 'joyful_activation', 'tension',\n",
        "          'sadness', 'mood', 'liked', 'disliked', 'age', 'gender', 'mother tongue']\n",
        "    annot_subset = annot[['track id', 'amazement', 'solemnity', 'tenderness',\n",
        "          'nostalgia', 'calmness', 'power', 'joyful_activation', 'tension',\n",
        "          'sadness', 'mood', 'liked', 'disliked']]\n",
        "    #CSV DATA\n",
        "    print (\"create csv data\")\n",
        "    final_data = createEmotionData(annot_subset)\n",
        "\n",
        "    print (\"create music data\")\n",
        "    bigX, bigY = createMusicData(musicPath)\n",
        "\n",
        "    print (\"finished loading data\")\n",
        "\n",
        "    #CREATE MODEL\n",
        "\n",
        "    print (\"create model\")\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    model = build_seamise_model_with_functional()\n",
        "    tf.keras.utils.plot_model(model)\n",
        "    keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "    opt = tf.keras.optimizers.Adam(\n",
        "        learning_rate=0.0005,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-07,\n",
        "        amsgrad=False,\n",
        "        name='adam',\n",
        "    )\n",
        "\n",
        "    model.compile(optimizer=opt, loss='mae') #, metrics=[tf.keras.metrics.Accuracy()])\n",
        "\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        history = model.fit(\n",
        "            x=[bigX, final_data],\n",
        "            y=bigY,\n",
        "            validation_split = 0.2,\n",
        "            batch_size=3,\n",
        "            epochs=7,\n",
        "            callbacks=[callback])\n",
        "        \n",
        "    model.save('/content/drive/MyDrive/emotifymusicMD/mgenModel.h5')\n",
        "\n",
        "    #PREDICT\n",
        "\n",
        "    predicted_notes = predict(bigX, final_data, new_model)\n",
        "\n",
        "    print (\"converting output to midi\")\n",
        "    convert_to_midi(predicted_notes)\n",
        "\n",
        "    !apt install fluidsynth\n",
        "    !cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
        "    !fluidsynth -ni font.sf2 music.mid -F output.wav -r 44100\n",
        "    from IPython.display import Audio\n",
        "    Audio('output.wav')"
      ],
      "metadata": {
        "id": "pfBnawLobrKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6vDXLKiwzG4",
        "outputId": "eb9e1428-14c8-409d-9532-b929c879eb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "new_model = tf.keras.models.load_model('your_neuralnet_model.h5')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KApCt1BRpYZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "predict(bigX, final_data)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a2g_3UtmfPi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hide"
      ],
      "metadata": {
        "id": "dMTnOg_Ibo3V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztW0vz4K5gUR"
      },
      "source": [
        "Music Audio Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTt_md005gUS"
      },
      "outputs": [],
      "source": [
        "def read_midi(file):\n",
        "    \n",
        "    print(\"Loading Music File:\",file)\n",
        "    \n",
        "    notes=[]\n",
        "    notes_to_parse = None\n",
        "    \n",
        "    #parsing a midi file\n",
        "    midi = converter.parse(file)\n",
        "  \n",
        "    #grouping based on different instruments\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "\n",
        "    #Looping over all the instruments\n",
        "    for part in s2.parts:\n",
        "    \n",
        "        #select elements of only piano\n",
        "        #if 'Piano' in str(part): \n",
        "        \n",
        "        notes_to_parse = part.recurse() \n",
        "  \n",
        "        #finding whether a particular element is note or a chord\n",
        "        for element in notes_to_parse:\n",
        "            \n",
        "            #note\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            \n",
        "            #chord\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return np.array(notes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBoT40HI5gUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "da3b50cd-4e55-4f52-9d5f-75720bd63f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Music File: /content/drive/MyDrive/classicalmidi/29.mp3.mid\n",
            "Loading Music File: /content/drive/MyDrive/classicalmidi/7.mp3.mid\n",
            "Loading Music File: /content/drive/MyDrive/classicalmidi/27.mp3.mid\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5124e740ef21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#reading each midi file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnotes_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mread_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-5124e740ef21>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#reading each midi file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnotes_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mread_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-5382cd4bd863>\u001b[0m in \u001b[0;36mread_midi\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#parsing a midi file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmidi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#grouping based on different instruments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(value, *args, **keywords)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalueStr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         return parseFile(valueStr, number=number, format=m21Format,\n\u001b[0;32m-> 1127\u001b[0;31m                          forceSource=forceSource, **keywords)\n\u001b[0m\u001b[1;32m   1128\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalueStr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         return parseFile(common.cleanpath(valueStr), number=number, format=m21Format,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnPathlib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforceSource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(self, fp, number, format, forceSource, storePickle, **keywords)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0menvironLocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintDebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading original version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFileNoPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwritePickle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfpPickle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstorePickle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;31m# save the stream to disk...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparseFileNoPickle\u001b[0;34m(self, fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mConverterFileException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File is not in a correct format: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/converter/subConverters.py\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(self, fp, number, **keywords)\u001b[0m\n\u001b[1;32m    980\u001b[0m         '''\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mmusic21\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranslate\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmidiTranslate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mmidiTranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidiFilePathToStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/midi/translate.py\u001b[0m in \u001b[0;36mmidiFilePathToStream\u001b[0;34m(filePath, inputM21, **keywords)\u001b[0m\n\u001b[1;32m   1973\u001b[0m     \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m     \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmidiFileToStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputM21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/midi/translate.py\u001b[0m in \u001b[0;36mmidiFileToStream\u001b[0;34m(mf, inputM21, quantizePost, **keywords)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             \u001b[0mquantizePost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantizePost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m                             \u001b[0minputM21\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                             **keywords)\n\u001b[0m\u001b[1;32m   2116\u001b[0m         \u001b[0;31m#s._setMidiTracks(mf.tracks, mf.ticksPerQuarterNote)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/midi/translate.py\u001b[0m in \u001b[0;36mmidiTracksToStreams\u001b[0;34m(midiTracks, ticksPerQuarter, quantizePost, inputM21, **keywords)\u001b[0m\n\u001b[1;32m   1876\u001b[0m                               \u001b[0mquantizePost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                               \u001b[0minputM21\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstreamPart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1878\u001b[0;31m                               **keywords)\n\u001b[0m\u001b[1;32m   1879\u001b[0m \u001b[0;31m#             streamPart._setMidiTracksPart(mt,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m \u001b[0;31m#                 ticksPerQuarter=ticksPerQuarter, quantizePost=quantizePost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/midi/translate.py\u001b[0m in \u001b[0;36mmidiTrackToStream\u001b[0;34m(mt, ticksPerQuarter, quantizePost, inputM21, **keywords)\u001b[0m\n\u001b[1;32m   1653\u001b[0m                    \u001b[0mprocessOffsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                    \u001b[0mprocessDurations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m                    inPlace=True)\n\u001b[0m\u001b[1;32m   1656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvoicesRequired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/stream/__init__.py\u001b[0m in \u001b[0;36mquantize\u001b[0;34m(self, quarterLengthDivisors, processOffsets, processDurations, inPlace, recurse)\u001b[0m\n\u001b[1;32m   8236\u001b[0m         \u001b[0museStreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreturnStream\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8238\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturnStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8239\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'Stream'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8240\u001b[0m                     \u001b[0museStreams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/stream/__init__.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, streamsOnly, restoreActiveSites, classFilter, skipSelf, includeSelf)\u001b[0m\n\u001b[1;32m   7049\u001b[0m                                         \u001b[0mstreamsOnly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstreamsOnly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7050\u001b[0m                                         \u001b[0mrestoreActiveSites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestoreActiveSites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7051\u001b[0;31m                                         \u001b[0mincludeSelf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincludeSelf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7052\u001b[0m                                         )\n\u001b[1;32m   7053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassFilter\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/stream/iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, srcStream, filterList, restoreActiveSites, activeInformation, streamsOnly, includeSelf, ignoreSorting)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                          \u001b[0mrestoreActiveSites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestoreActiveSites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m                          \u001b[0mactiveInformation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactiveInformation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m                          \u001b[0mignoreSorting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignoreSorting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m                         )\n\u001b[1;32m   1342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'lastYielded'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiveInformation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/stream/iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, srcStream, filterList, restoreActiveSites, activeInformation, ignoreSorting)\u001b[0m\n\u001b[1;32m     84\u001b[0m                  ignoreSorting=False):\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignoreSorting\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msrcStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misSorted\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msrcStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoSort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msrcStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrcStream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrcStream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/stream/__init__.py\u001b[0m in \u001b[0;36msort\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m   6442\u001b[0m         \u001b[0;31m# experimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misSorted\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6444\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6445\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endElements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/music21/sorting.py\u001b[0m in \u001b[0;36m__lt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__lt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__lt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matEnd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/fractions.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numerator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_denominator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRational\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m             return (a._numerator == b.numerator and\n\u001b[1;32m    573\u001b[0m                     a._denominator == b.denominator)\n",
            "\u001b[0;32m/usr/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#Array Processing\n",
        "import numpy as np\n",
        "\n",
        "#specify the path\n",
        "path =\"/content/drive/MyDrive/classicalmidi/\"\n",
        "\n",
        "\n",
        "#read all the filenames\n",
        "files=[i for i in os.listdir(path) ]\n",
        "\n",
        "#reading each midi file\n",
        "notes_array = np.array([read_midi(path+i) for i in files])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isR8U0Lo5gUS"
      },
      "outputs": [],
      "source": [
        "#converting 2D array into 1D array\n",
        "notes_ = [element for note_ in notes_array for element in note_]\n",
        "\n",
        "#No. of unique notes\n",
        "unique_notes = list(set(notes_))\n",
        "print(len(unique_notes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGZf6F945gUT"
      },
      "outputs": [],
      "source": [
        "#importing library\n",
        "from collections import Counter\n",
        "\n",
        "#computing frequency of each note\n",
        "freq = dict(Counter(notes_))\n",
        "\n",
        "#library for visualiation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#consider only the frequencies\n",
        "no=[count for _,count in freq.items()]\n",
        "\n",
        "#set the figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "#plot\n",
        "plt.hist(no)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q39n45lV5gUT"
      },
      "outputs": [],
      "source": [
        "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
        "print(len(frequent_notes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlRM1trE5gUT"
      },
      "outputs": [],
      "source": [
        "#concatenating all 100 audio files\n",
        "new_music=[]\n",
        "\n",
        "for notes in notes_array:\n",
        "    temp=[]\n",
        "    for note_ in notes:\n",
        "        if note_ in frequent_notes:\n",
        "            temp.append(note_)            \n",
        "    new_music.append(temp)\n",
        "    \n",
        "new_music = np.array(new_music)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLb0gUIEZ-7g"
      },
      "outputs": [],
      "source": [
        "#cutting all files to 1000\n",
        "diff = 0\n",
        "\n",
        "for i in range(100):\n",
        "    diff = len(new_music[i]) - 1000\n",
        "    if (diff > 0):\n",
        "      new_music[i] = new_music[i][:-diff]\n",
        "    elif (diff < 0):\n",
        "      for j in range(-diff):\n",
        "        new_music[i].append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqHggsL3N8aK"
      },
      "outputs": [],
      "source": [
        "list(set(new_music.ravel()[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DXfHwSQPqV5"
      },
      "outputs": [],
      "source": [
        "np.unique(np.asarray([new_music[i][0:1000] for i in range(5)]).reshape(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_FmER6WNRoL"
      },
      "outputs": [],
      "source": [
        "#DICTIONARY unique notes --> numbers\n",
        "unique_x = np.unique(np.asarray([new_music[i][0:1001] for i in range(100)]).reshape(-1))\n",
        "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR_1jwgyRDsh"
      },
      "outputs": [],
      "source": [
        "x_note_to_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPj5QyqzNiKA"
      },
      "outputs": [],
      "source": [
        "#preparing input sequences\n",
        "x_seq=[]\n",
        "for i in new_music:\n",
        "    temp=[]\n",
        "    for j in i:\n",
        "        #assigning unique integer to every note\n",
        "        temp.append(x_note_to_int[str(j)])\n",
        "    x_seq.append(temp)\n",
        "\n",
        "x_seq = np.array(x_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3e1imkHyegg"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slCMBpSxyb4R"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "window_size = 32 #increase\n",
        "for i in tqdm(x_seq):\n",
        "    this_x_ = [] # placeholder\n",
        "    for j in range(len(i)-window_size):\n",
        "        this_x_.append(i[j:(j+window_size)])\n",
        "    x.append(this_x_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAneNobxzq4Q"
      },
      "outputs": [],
      "source": [
        "x_arr = np.asarray(x)\n",
        "x_arr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGkfM0in0JsB"
      },
      "outputs": [],
      "source": [
        "x_arr_resh = x_arr.reshape((100, 968, 32, 1))\n",
        "x_arr_resh.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlSuPMbo0P_L"
      },
      "outputs": [],
      "source": [
        "bigX, bigY = x_arr_resh[:, 0:967, :, :], x_arr_resh[:, 967, :, :]\n",
        "bigY = bigY.reshape((100, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGqCa4vstiLj"
      },
      "source": [
        "Emotion Categorical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGNVRuLVm8z6"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq57uVdFnCK5"
      },
      "outputs": [],
      "source": [
        "# directory\n",
        "path = '/content/drive/MyDrive/emotifymusicMD/'\n",
        "os.chdir(path)\n",
        "#os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l16PcbHTnL52",
        "outputId": "7fd2abd5-e4c9-491d-8099-d69617e985b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2688, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# annotation data\n",
        "annot = pd.read_csv('emotifyannotationsdata.csv', nrows = 2688)\n",
        "annot.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV1v2vZVpwkV"
      },
      "outputs": [],
      "source": [
        "annot.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQAJn2hHnRXc"
      },
      "outputs": [],
      "source": [
        "# subset\n",
        "annot.columns = ['track id', 'genre', 'amazement', 'solemnity', 'tenderness',\n",
        "       'nostalgia', 'calmness', 'power', 'joyful_activation', 'tension',\n",
        "       'sadness', 'mood', 'liked', 'disliked', 'age', 'gender', 'mother tongue']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL5jC2P3ngoM"
      },
      "outputs": [],
      "source": [
        "# subset only numerical columns\n",
        "annot_subset = annot[['track id', 'amazement', 'solemnity', 'tenderness',\n",
        "       'nostalgia', 'calmness', 'power', 'joyful_activation', 'tension',\n",
        "       'sadness', 'mood', 'liked', 'disliked']]\n",
        "\n",
        "annot_subset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6vPanVvnw3G"
      },
      "outputs": [],
      "source": [
        "# groupby + taking average + rounding to nearest int\n",
        "new_data = annot_subset.groupby('track id').mean().round(0)\n",
        "new_data.head(100)\n",
        "#new_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzxd29KSoM5H"
      },
      "outputs": [],
      "source": [
        "# add track id as a new col\n",
        "new_data['track_id'] = new_data.index\n",
        "new_data.head(3)\n",
        "new_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbMFhSwuoqaX"
      },
      "outputs": [],
      "source": [
        "# subset\n",
        "final_data = new_data[['track_id', 'calmness', 'power']]\n",
        "final_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFCHhEHuqC-A"
      },
      "outputs": [],
      "source": [
        "# save\n",
        "final_data.to_csv('final_data_for_annotation.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_wZKLDFQI11"
      },
      "outputs": [],
      "source": [
        "final_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# redefine model\n",
        "\n"
      ],
      "metadata": {
        "id": "TmjNz5paWp4I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T46ovQrV0oFd"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "def load_music_emotions(inputPath):\n",
        "\t# initialize the list of column names in the CSV file and then\n",
        "\t# load it using Pandas\n",
        "\tcols = [\"track_id\", \"calmness\", \"power\"]\n",
        "\tdf = pd.read_csv(inputPath, sep=\" \", header=None, names=cols)\n",
        "\t\n",
        "\t# return the data frame\n",
        "\treturn df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LZUugFLILXL"
      },
      "outputs": [],
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vb8RXs9eraj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title PICKLE FILE\n",
        "import os\n",
        "import pickle\n",
        "path = '/content/drive/MyDrive/emotifymusicMD/'\n",
        "os.chdir(path)\n",
        "os.listdir()  \n",
        "a = (bigX, final_data, bigY)\n",
        "\n",
        "with open('classical_data.pkl', 'wb') as handle:\n",
        "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('classical_data.pkl', 'rb') as handle:\n",
        "    b = pickle.load(handle)\n",
        "bigX, final_data, bigY = b \n",
        "bigX.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to save your model by using\n",
        "\n",
        "```\n",
        "# save model: it must be .h5 format\n",
        "model.save('your_neuralnet_model.h5')\n",
        "```"
      ],
      "metadata": {
        "id": "xrz_opEtYSfO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp2-hYPByXMd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tycsBf9WyT1C",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.title('loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume that your model is trained and saved somewhere. Then when you want to call it, just use the following code\n",
        "\n",
        "```\n",
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model = tf.keras.models.load_model('your_neuralnet_model.h5')\n",
        "```"
      ],
      "metadata": {
        "id": "6d2hhcwcZjn2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyqD0yelDlJL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "output_of_ONE_SONG = model.predict([bigX[0:1], final_data[0:1]])\n",
        "output_of_ONE_SONG.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYONT-g4pM0d",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "intSong = list(np.round(output_of_ONE_SONG[0]*100, ).astype(int))\n",
        "\n",
        "print(intSong)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQKZ2e-v6bFF"
      },
      "source": [
        "load data & train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvA2I3ggYafy",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#DO I NEED THIS STEP IT DOESNT WORK LMAOO\n",
        "\"\"\"\n",
        "#@title\n",
        "import random\n",
        "ind = np.random.randint(0,len(bigX)-1)\n",
        "\n",
        "#random_music = bigX[ind]\n",
        "no_of_timesteps = 32\n",
        "\n",
        "predictions=[]\n",
        "#controls length of piece\n",
        "for i in range(10):\n",
        "\n",
        "    #random_music = random_music.reshape(1,no_of_timesteps)\n",
        "\n",
        "    prob  = model.predict(random_music)[0]\n",
        "    y_pred= np.argmax(prob,axis=0)\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
        "    random_music = random_music[1:]\n",
        "    \n",
        "print(predictions)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJPFG6TKYdXj"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
        "predicted_notes = [x_int_to_note[i] for i in intSong]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7e9yETPYvrT"
      },
      "outputs": [],
      "source": [
        "convert_to_midi(predicted_notes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vMwV5qoNY1KP"
      },
      "outputs": [],
      "source": [
        "!apt install fluidsynth\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
        "!fluidsynth -ni font.sf2 music.mid -F output.wav -r 44100\n",
        "from IPython.display import Audio\n",
        "Audio('output.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "kkaFwLBEc1ts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X9jg3TYTc3-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# app"
      ],
      "metadata": {
        "id": "sJ73_2-GbtWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre = 'classical' #@param [\"classical\", \"electronic\", \"pop\"]\n",
        "emotion = 'relaxation' #@param [\"relaxation\", \"energy\", \"focus\"]"
      ],
      "metadata": {
        "id": "eCeAjyipbt65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "magic_function() # this will have 5a-c inside but it's defined above and hidden so noone will see it."
      ],
      "metadata": {
        "id": "JN9zm_O9b9Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsCbS9Cqb-bB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dMTnOg_Ibo3V"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}